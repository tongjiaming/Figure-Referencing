{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2924e3b-9081-4829-a8db-a7626d6378fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fb13b510-931b-4dea-9d06-c417a88f0a17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install accelerate\n",
    "from transformers import AutoTokenizer, OPTForCausalLM, StoppingCriteria\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b9822-747c-4dcf-9ea0-cc1e588a8f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/galactica-6.7b\")\n",
    "model = OPTForCausalLM.from_pretrained(\"facebook/galactica-6.7b\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6567ff7a-ca8e-40fc-ab9b-5d4bc678278a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(221)]\n"
     ]
    }
   ],
   "source": [
    "stop_words_ids = [\n",
    "    tokenizer(stop_word, return_tensors='pt')['input_ids'].squeeze() for stop_word in ['\\n']]\n",
    "\n",
    "class StoppingCriteriaSub(StoppingCriteria):\n",
    "    def __init__(self, stops = []):\n",
    "      super().__init__()\n",
    "      self.stops = stops\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n",
    "      for stop in self.stops:\n",
    "          if stop == input_ids[0][-1]:\n",
    "              print(stop)\n",
    "              print(input_ids)\n",
    "              return True\n",
    "      return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaSub(stop_words_ids)\n",
    "print(stop_words_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a1b9447-5701-42c5-9aa7-d9ebc7d3fef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer architecture [START_REF] Attention is All you Need, Vaswani[END_REF] is a sequence-to-sequence model that uses self\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The Transformer architecture [START_REF]\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids, max_new_tokens=20, stopping_criteria=[stopping_criteria])\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e381ac5-5d7c-4f31-bcc6-7e22d46ea691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(221)\n",
      "tensor([[  592,  1482,    37,  2044,  1586,   286,  2191,   658,  1918,   312,\n",
      "          1908, 10011,    36,   221,   592, 33223,   299,   286,  4374,  4789,\n",
      "           301,   286,  1504,  9553,  1502,   391,   221,   221,  1095,   243,\n",
      "            39,    48, 10862,   658,  1918,   312,  1908, 10011,    36,   221]])\n",
      "The Figure/Table shows the relationship between population and average income.\n",
      "The caption of the figure mentioned in the above sentence should be\n",
      "\n",
      "Figure 1: Relationship between population and average income.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The Figure/Table shows the relationship between population and average income.\\n\\\n",
    "The caption of the figure mentioned in the above sentence should be\\n\\n\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids, max_new_tokens=20, stopping_criteria=[stopping_criteria])\n",
    "# outputs = model.generate(input_ids, max_new_tokens=20)\n",
    "# print(outputs[0])\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f232eda8-2cb7-44f6-819c-983763fe1c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  592,  1482,    37,  2044,  1586,   286,  2191,   658,  1918,   312,\n",
      "         1908, 10011,    36,   221,   592, 33223,   299,   286,  4374,  4789,\n",
      "          301,   286,  1504,  9553,  1502,   391,    48,   243,    24,   592,\n",
      "         1482,    37,  2044,  1586,   286,  2191,   658,  1918,   312,  1908,\n",
      "        10011,    36,    24,   221])\n",
      "The Figure/Table shows the relationship between population and average income.\n",
      "The caption of the figure mentioned in the above sentence should be: \"The Figure/Table shows the relationship between population and average income.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eos_token_id = int(tokenizer('\\n', return_tensors=\"pt\").input_ids[0][0])\n",
    "input_text = \"The Figure/Table shows the relationship between population and average income.\\n\\\n",
    "The caption of the figure mentioned in the above sentence should be\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "outputs = model.generate(input_ids, min_new_tokens=5, max_new_tokens=20, eos_token_id=eos_token_id)\n",
    "# outputs = model.generate(input_ids, max_new_tokens=20)\n",
    "print(outputs[0])\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
